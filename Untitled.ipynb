{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.data import Argoverse_Data\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now = 2020-04-20 23:57:07.737882\n",
      "date and time = 20-04-2020::23:57:07\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    " \n",
    "print(\"now =\", now)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%d-%m-%Y::%H:%M:%S\")\n",
    "print(\"date and time =\", dt_string)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "argoverse_val = Argoverse_Data('../deep_prediction/data/val/data/')\n",
    "sample_data = Argoverse_Data('../deep_prediction/forecasting_sample/data/')\n",
    "# sample_size = len(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seq_path': ['../deep_prediction/forecasting_sample/data/3861.csv'], 'train_agent': tensor([[[ 0.0000e+00,  0.0000e+00],\n",
      "         [ 1.2543e+00, -5.8349e-03],\n",
      "         [ 2.5415e+00,  5.2247e-02],\n",
      "         [ 3.8429e+00,  4.2080e-02],\n",
      "         [ 5.0819e+00, -3.5067e-03],\n",
      "         [ 6.3467e+00, -5.5566e-03],\n",
      "         [ 7.7470e+00,  5.4335e-02],\n",
      "         [ 8.9515e+00,  8.9636e-03],\n",
      "         [ 1.0177e+01,  2.3521e-02],\n",
      "         [ 1.1624e+01, -7.5860e-03],\n",
      "         [ 1.2986e+01, -1.2566e-02],\n",
      "         [ 1.4298e+01, -2.0534e-02],\n",
      "         [ 1.5616e+01, -2.9549e-02],\n",
      "         [ 1.6543e+01, -1.2989e-01],\n",
      "         [ 1.8358e+01, -1.3104e-02],\n",
      "         [ 1.9748e+01,  2.6593e-02],\n",
      "         [ 2.0951e+01,  4.1451e-02],\n",
      "         [ 2.2494e+01,  4.4839e-02],\n",
      "         [ 2.3304e+01, -1.5529e-02],\n",
      "         [ 2.4562e+01,  0.0000e+00]]]), 'gt_agent': tensor([[[26.0515,  0.0863],\n",
      "         [27.5043,  0.0856],\n",
      "         [28.8372,  0.1682],\n",
      "         [30.0642,  0.1814],\n",
      "         [31.7344,  0.2660],\n",
      "         [33.0048,  0.3933],\n",
      "         [34.6810,  0.4462],\n",
      "         [35.8799,  0.5149],\n",
      "         [36.9755,  0.5629],\n",
      "         [38.4827,  0.6598],\n",
      "         [40.0006,  0.7202],\n",
      "         [41.7650,  0.7079],\n",
      "         [43.2841,  0.8059],\n",
      "         [44.4986,  1.0293],\n",
      "         [46.0197,  1.1625],\n",
      "         [47.6686,  1.2432],\n",
      "         [49.2600,  1.3055],\n",
      "         [50.7577,  1.3999],\n",
      "         [52.3330,  1.4648],\n",
      "         [53.9508,  1.5140],\n",
      "         [55.2940,  1.6155],\n",
      "         [57.1822,  1.6572],\n",
      "         [58.3578,  1.7619],\n",
      "         [59.9709,  1.8188],\n",
      "         [61.5402,  1.8656],\n",
      "         [63.1457,  1.9519],\n",
      "         [64.7493,  2.0124],\n",
      "         [66.4965,  1.9722],\n",
      "         [67.9476,  2.2101],\n",
      "         [69.9002,  1.7581]]]), 'gt_unnorm_agent': tensor([[[1832.6304,  436.2876],\n",
      "         [1833.7366,  437.2292],\n",
      "         [1834.6976,  438.1566],\n",
      "         [1835.6229,  438.9624],\n",
      "         [1836.8394,  440.1100],\n",
      "         [1837.7239,  441.0309],\n",
      "         [1838.9655,  442.1583],\n",
      "         [1839.8334,  442.9881],\n",
      "         [1840.6362,  443.7353],\n",
      "         [1841.7207,  444.7865],\n",
      "         [1842.8368,  445.8169],\n",
      "         [1844.1879,  446.9518],\n",
      "         [1845.2805,  448.0116],\n",
      "         [1846.0601,  448.9693],\n",
      "         [1847.1315,  450.0573],\n",
      "         [1848.3342,  451.1881],\n",
      "         [1849.5051,  452.2676],\n",
      "         [1850.5839,  453.3108],\n",
      "         [1851.7408,  454.3820],\n",
      "         [1852.9404,  455.4686],\n",
      "         [1853.8970,  456.4170],\n",
      "         [1855.3071,  457.6733],\n",
      "         [1856.1340,  458.5154],\n",
      "         [1857.3250,  459.6050],\n",
      "         [1858.4891,  460.6584],\n",
      "         [1859.6553,  461.7654],\n",
      "         [1860.8367,  462.8514],\n",
      "         [1862.1926,  463.9540],\n",
      "         [1863.1428,  465.0761],\n",
      "         [1864.9222,  465.9985]]]), 'rotation': tensor([[[ 0.7612,  0.6486],\n",
      "         [-0.6486,  0.7612]]]), 'translation': tensor([[-1812.8568,  -419.3260]]), 'city': ['PIT']}\n"
     ]
    }
   ],
   "source": [
    "sample_loader = DataLoader(sample_data, batch_size=1, shuffle=True)\n",
    "dataiter = iter(sample_loader)\n",
    "traj = dataiter.next()\n",
    "print(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_batches(dataset_size, batch_size):\n",
    "#     the_batches = []\n",
    "#     batch = [0,0]\n",
    "    \n",
    "#     n_batches = int(np.floor(dataset_size/batch_size))\n",
    "    \n",
    "#     i = 0\n",
    "#     for n in range(0,n_batches,1):\n",
    "#         batch[0] = i\n",
    "#         batch[1] = i + batch_size -1\n",
    "#         the_batches.append([*batch])\n",
    "#         i = i + batch_size\n",
    "#     return the_batches        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argoverse_train = Argoverse_Data('../deep_prediction/data/train/data/')\n",
    "# argoverse_test = Argoverse_Data('../deep_prediction/data/test/data/')\n",
    "# argoverse_val = Argoverse_Data('../deep_prediction/data/val/data/')\n",
    "# argoverse_sample = Argoverse_Data('../deep_prediction/forecasting_sample/data/')\n",
    "# print(argoverse_val[0]['train_agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_size = len(argoverse_val)\n",
    "# print(val_size)\n",
    "\n",
    "# dataset_obsv = []\n",
    "# i = 0\n",
    "# for data in argoverse_val:\n",
    "#     dataset_obsv.append(data['train_agent'])\n",
    "#     i +=1\n",
    "#     print(i)\n",
    "\n",
    "# batch_size = 32\n",
    "# val_loader = DataLoader(argoverse_val, batch_size=val_size)\n",
    "# val_dataiter = iter(val_loader)\n",
    "# val_dataset = val_dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_obsv = torch.stack(dataset_obsv)\n",
    "# the_batches = get_batches(len(stacked_obsv), 32)\n",
    "# n_past = stacked_obsv.shape[1]\n",
    "# print(n_past)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the_batches = get_batches(len(val_dataset), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_loader = DataLoader(sample_data, batch_size=1, shuffle=True)\n",
    "# dataiter = iter(sample_loader)\n",
    "# traj = dataiter.next()\n",
    "# obsv = [traj)\n",
    "# print(torch.stack((traj['train_agent'],traj['train_agent'])))\n",
    "# print(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_data(traj):\n",
    "    obsv = traj['train_agent']\n",
    "    pred = traj['gt_agent']\n",
    "        \n",
    "    return obsv, pred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sample_data))\n",
    "dataset_obsv, dataset_pred = accumulate_data(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(val_loader)\n",
    "traj = dataiter.next()\n",
    "# print(traj)\n",
    "obsv, pred = accumulate_data(traj)\n",
    "\n",
    "# print(traj['train_agent'].shape)\n",
    "# print(traj['gt_agent'].shape)\n",
    "# print(traj['gt_unnorm_agent'].shape)\n",
    "# print(obsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment tensors of positions into positions+velocity\n",
    "def get_traj_4d(obsv_p, pred_p):\n",
    "    obsv_v = obsv_p[:, 1:] - obsv_p[:, :-1]\n",
    "    obsv_v = torch.cat([obsv_v[:, 0].unsqueeze(1), obsv_v], dim=1)\n",
    "    obsv_4d = torch.cat([obsv_p, obsv_v], dim=2)\n",
    "    if len(pred_p) == 0: return obsv_4d\n",
    "    pred_p_1 = torch.cat([obsv_p[:, -1].unsqueeze(1), pred_p[:, :-1]], dim=1)\n",
    "    pred_v = pred_p - pred_p_1\n",
    "    pred_4d = torch.cat([pred_p, pred_v], dim=2)\n",
    "    return obsv_4d, pred_4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsv4d, pred4d = get_traj_4d(obsv, pred)\n",
    "print(obsv4d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
